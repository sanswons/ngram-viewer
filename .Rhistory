shiny::runApp()
runApp()
runApp()
library(tm)
library(tm)
library(ngram)
library(ggplot2)
extract_texts = function(path){
filenames = list.files(path)
texts_df = data.frame(year = character(), text = character() , stringsAsFactors = FALSE)
for (i in 1:length(filenames))
{
if (is.na(as.numeric(filenames[i]))==FALSE)
{
year = filenames[i]
path = paste(c('../task/', year,  '/'), collapse = '')
textnames = list.files(path)
for (textname in textnames)
{
fulltext = ''
if (endsWith(textname,'.txt'))
{
path = paste(c('../task/', year, '/', textname),collapse = '')
text = cleaning(scan(path, what = 'character'))
fulltext = paste(c(fulltext, text), collapse = ';')
}
}
newRow = data.frame(year, fulltext, stringsAsFactors = FALSE)
texts_df = rbind(texts_df, newRow)
}
}
print('Created df')
return(texts_df)
}
cleaning = function(text){
text = concatenate(text, collapse = ' ')
text = tolower(text)
text = gsub('http\\S+\\s*', ',', text)
text = gsub("[[:punct:]]", "", text)
text = gsub('\\s+',' ', text)
return (text)
}
create_ngrams_allbooks = function(df, max_ngrams){
nmax = max_ngrams
for (i in 1:length(df$year))
{
for (j in 1:nmax)
{
output = ngram(str = df[i,2], n = j)
table = get.phrasetable(output)
filename = paste(c('../ngrams/',df[i,1],'_',j),collapse = '')
write.csv(as.data.frame(table), file = filename)
}
}
print('Created csv files')
}
search_ngrams = function(phrase, nyears, filenames){
print('Searching')
#print(phrase)
phrase = tolower(paste(c(trimws(phrase), ' '),collapse = ''))
num_words = as.character(length(strsplit(phrase,split = " ")[[1]]))
freqs_allbooks = data.frame()
for (i in 1:length(nyears))
{
path = paste(c('../ngrams/',nyears[i],'_',num_words), collapse = '')
freqs = read.csv(path)
freqs$ngrams = as.character(freqs$ngrams)
index = match(phrase,freqs$ngrams,nomatch = 0)
if (index==0)
{
frequency = 0
}
else
{
frequency = freqs$freq[index]
}
newRow = data.frame(year = nyears[i], freq = frequency, phrase = phrase, stringsAsFactors = FALSE)
freqs_allbooks = rbind(freqs_allbooks,newRow)
}
#print(freqs_allbooks)
return(freqs_allbooks)
}
create_plots = function(query){
filenames = list.files('../ngrams/')
phrases = strsplit(query,split = ",")
print('Started')
freqs = data.frame()
for (i in 1:length(phrases[[1]])){
newfreqs = search_ngrams(phrases[[1]][i], texts_df$year, filenames)
freqs = rbind(freqs, newfreqs)
}
print(freqs)
p = ggplot(data = freqs, aes( x = year, y = freq, colour = phrase, group = phrase)) + geom_point(size = 3) + geom_line(size = 1)
print(p)
return (p)
}
texts_df = extract_texts('../task/')
create_ngrams_allbooks(texts_df, max_ngrams = 5)
#create_plots('we, not')
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
texts_df = extract_texts('task/')
#
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# find the n-gram length
num_words = as.character(length(strsplit(phrase,split = " ")[[1]]))
runApp()
runApp()
runApp()
source('C:/Users/sanja/Desktop/Sanjana/books/CSE/Machine Learning/Projects/Moveworks/utils.R')
#Remove extra spaces
phrase = gsub('\\s+',' ', phrase)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
